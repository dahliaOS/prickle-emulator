/* This file is autogenerated by tracetool, do not edit. */

#ifndef TRACE_HW_BLOCK_GENERATED_TRACERS_H
#define TRACE_HW_BLOCK_GENERATED_TRACERS_H

#include "qemu-common.h"
#include "trace/control.h"

extern TraceEvent _TRACE_FDC_IOPORT_READ_EVENT;
extern TraceEvent _TRACE_FDC_IOPORT_WRITE_EVENT;
extern TraceEvent _TRACE_PFLASH_RESET_EVENT;
extern TraceEvent _TRACE_PFLASH_READ_EVENT;
extern TraceEvent _TRACE_PFLASH_WRITE_EVENT;
extern TraceEvent _TRACE_PFLASH_TIMER_EXPIRED_EVENT;
extern TraceEvent _TRACE_PFLASH_DATA_READ8_EVENT;
extern TraceEvent _TRACE_PFLASH_DATA_READ16_EVENT;
extern TraceEvent _TRACE_PFLASH_DATA_READ32_EVENT;
extern TraceEvent _TRACE_PFLASH_DATA_WRITE_EVENT;
extern TraceEvent _TRACE_PFLASH_MANUFACTURER_ID_EVENT;
extern TraceEvent _TRACE_PFLASH_DEVICE_ID_EVENT;
extern TraceEvent _TRACE_PFLASH_DEVICE_INFO_EVENT;
extern TraceEvent _TRACE_VIRTIO_BLK_REQ_COMPLETE_EVENT;
extern TraceEvent _TRACE_VIRTIO_BLK_RW_COMPLETE_EVENT;
extern TraceEvent _TRACE_VIRTIO_BLK_HANDLE_WRITE_EVENT;
extern TraceEvent _TRACE_VIRTIO_BLK_HANDLE_READ_EVENT;
extern TraceEvent _TRACE_VIRTIO_BLK_SUBMIT_MULTIREQ_EVENT;
extern TraceEvent _TRACE_HD_GEOMETRY_LCHS_GUESS_EVENT;
extern TraceEvent _TRACE_HD_GEOMETRY_GUESS_EVENT;
extern TraceEvent _TRACE_NVME_IRQ_MSIX_EVENT;
extern TraceEvent _TRACE_NVME_IRQ_PIN_EVENT;
extern TraceEvent _TRACE_NVME_IRQ_MASKED_EVENT;
extern TraceEvent _TRACE_NVME_DMA_READ_EVENT;
extern TraceEvent _TRACE_NVME_RW_EVENT;
extern TraceEvent _TRACE_NVME_CREATE_SQ_EVENT;
extern TraceEvent _TRACE_NVME_CREATE_CQ_EVENT;
extern TraceEvent _TRACE_NVME_DEL_SQ_EVENT;
extern TraceEvent _TRACE_NVME_DEL_CQ_EVENT;
extern TraceEvent _TRACE_NVME_IDENTIFY_CTRL_EVENT;
extern TraceEvent _TRACE_NVME_IDENTIFY_NS_EVENT;
extern TraceEvent _TRACE_NVME_IDENTIFY_NSLIST_EVENT;
extern TraceEvent _TRACE_NVME_GETFEAT_VWCACHE_EVENT;
extern TraceEvent _TRACE_NVME_GETFEAT_NUMQ_EVENT;
extern TraceEvent _TRACE_NVME_SETFEAT_NUMQ_EVENT;
extern TraceEvent _TRACE_NVME_MMIO_INTM_SET_EVENT;
extern TraceEvent _TRACE_NVME_MMIO_INTM_CLR_EVENT;
extern TraceEvent _TRACE_NVME_MMIO_CFG_EVENT;
extern TraceEvent _TRACE_NVME_MMIO_AQATTR_EVENT;
extern TraceEvent _TRACE_NVME_MMIO_ASQADDR_EVENT;
extern TraceEvent _TRACE_NVME_MMIO_ACQADDR_EVENT;
extern TraceEvent _TRACE_NVME_MMIO_ASQADDR_HI_EVENT;
extern TraceEvent _TRACE_NVME_MMIO_ACQADDR_HI_EVENT;
extern TraceEvent _TRACE_NVME_MMIO_START_SUCCESS_EVENT;
extern TraceEvent _TRACE_NVME_MMIO_STOPPED_EVENT;
extern TraceEvent _TRACE_NVME_MMIO_SHUTDOWN_SET_EVENT;
extern TraceEvent _TRACE_NVME_MMIO_SHUTDOWN_CLEARED_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_DMA_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_PRPLIST_ENT_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_PRP2_ALIGN_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_PRP2_MISSING_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_PRP_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_NS_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_OPC_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_ADMIN_OPC_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_LBA_RANGE_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_DEL_SQ_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_CREATE_SQ_CQID_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_CREATE_SQ_SQID_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_CREATE_SQ_SIZE_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_CREATE_SQ_ADDR_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_CREATE_SQ_QFLAGS_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_DEL_CQ_CQID_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_DEL_CQ_NOTEMPTY_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_CREATE_CQ_CQID_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_CREATE_CQ_SIZE_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_CREATE_CQ_ADDR_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_CREATE_CQ_VECTOR_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_CREATE_CQ_QFLAGS_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_IDENTIFY_CNS_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_GETFEAT_EVENT;
extern TraceEvent _TRACE_NVME_ERR_INVALID_SETFEAT_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_CQ_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_SQ_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_NBARASQ_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_NBARACQ_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_ASQ_MISALIGNED_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_ACQ_MISALIGNED_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_PAGE_TOO_SMALL_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_PAGE_TOO_LARGE_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_CQENT_TOO_SMALL_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_CQENT_TOO_LARGE_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_SQENT_TOO_SMALL_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_SQENT_TOO_LARGE_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_ASQENT_SZ_ZERO_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_ACQENT_SZ_ZERO_EVENT;
extern TraceEvent _TRACE_NVME_ERR_STARTFAIL_EVENT;
extern TraceEvent _TRACE_NVME_UB_MMIOWR_MISALIGNED32_EVENT;
extern TraceEvent _TRACE_NVME_UB_MMIOWR_TOOSMALL_EVENT;
extern TraceEvent _TRACE_NVME_UB_MMIOWR_INTMASK_WITH_MSIX_EVENT;
extern TraceEvent _TRACE_NVME_UB_MMIOWR_RO_CSTS_EVENT;
extern TraceEvent _TRACE_NVME_UB_MMIOWR_SSRESET_W1C_UNSUPPORTED_EVENT;
extern TraceEvent _TRACE_NVME_UB_MMIOWR_SSRESET_UNSUPPORTED_EVENT;
extern TraceEvent _TRACE_NVME_UB_MMIOWR_CMBLOC_RESERVED_EVENT;
extern TraceEvent _TRACE_NVME_UB_MMIOWR_CMBSZ_READONLY_EVENT;
extern TraceEvent _TRACE_NVME_UB_MMIOWR_INVALID_EVENT;
extern TraceEvent _TRACE_NVME_UB_MMIORD_MISALIGNED32_EVENT;
extern TraceEvent _TRACE_NVME_UB_MMIORD_TOOSMALL_EVENT;
extern TraceEvent _TRACE_NVME_UB_MMIORD_INVALID_OFS_EVENT;
extern TraceEvent _TRACE_NVME_UB_DB_WR_MISALIGNED_EVENT;
extern TraceEvent _TRACE_NVME_UB_DB_WR_INVALID_CQ_EVENT;
extern TraceEvent _TRACE_NVME_UB_DB_WR_INVALID_CQHEAD_EVENT;
extern TraceEvent _TRACE_NVME_UB_DB_WR_INVALID_SQ_EVENT;
extern TraceEvent _TRACE_NVME_UB_DB_WR_INVALID_SQTAIL_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_REALIZE_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_CONNECT_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_DISCONNECT_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_UNREALIZE_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_SIZE_EVENT;
extern TraceEvent _TRACE_XEN_DISK_REALIZE_EVENT;
extern TraceEvent _TRACE_XEN_DISK_UNREALIZE_EVENT;
extern TraceEvent _TRACE_XEN_CDROM_REALIZE_EVENT;
extern TraceEvent _TRACE_XEN_CDROM_UNREALIZE_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_BLOCKDEV_ADD_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_BLOCKDEV_DEL_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_DEVICE_CREATE_EVENT;
extern TraceEvent _TRACE_XEN_BLOCK_DEVICE_DESTROY_EVENT;
extern uint16_t _TRACE_FDC_IOPORT_READ_DSTATE;
extern uint16_t _TRACE_FDC_IOPORT_WRITE_DSTATE;
extern uint16_t _TRACE_PFLASH_RESET_DSTATE;
extern uint16_t _TRACE_PFLASH_READ_DSTATE;
extern uint16_t _TRACE_PFLASH_WRITE_DSTATE;
extern uint16_t _TRACE_PFLASH_TIMER_EXPIRED_DSTATE;
extern uint16_t _TRACE_PFLASH_DATA_READ8_DSTATE;
extern uint16_t _TRACE_PFLASH_DATA_READ16_DSTATE;
extern uint16_t _TRACE_PFLASH_DATA_READ32_DSTATE;
extern uint16_t _TRACE_PFLASH_DATA_WRITE_DSTATE;
extern uint16_t _TRACE_PFLASH_MANUFACTURER_ID_DSTATE;
extern uint16_t _TRACE_PFLASH_DEVICE_ID_DSTATE;
extern uint16_t _TRACE_PFLASH_DEVICE_INFO_DSTATE;
extern uint16_t _TRACE_VIRTIO_BLK_REQ_COMPLETE_DSTATE;
extern uint16_t _TRACE_VIRTIO_BLK_RW_COMPLETE_DSTATE;
extern uint16_t _TRACE_VIRTIO_BLK_HANDLE_WRITE_DSTATE;
extern uint16_t _TRACE_VIRTIO_BLK_HANDLE_READ_DSTATE;
extern uint16_t _TRACE_VIRTIO_BLK_SUBMIT_MULTIREQ_DSTATE;
extern uint16_t _TRACE_HD_GEOMETRY_LCHS_GUESS_DSTATE;
extern uint16_t _TRACE_HD_GEOMETRY_GUESS_DSTATE;
extern uint16_t _TRACE_NVME_IRQ_MSIX_DSTATE;
extern uint16_t _TRACE_NVME_IRQ_PIN_DSTATE;
extern uint16_t _TRACE_NVME_IRQ_MASKED_DSTATE;
extern uint16_t _TRACE_NVME_DMA_READ_DSTATE;
extern uint16_t _TRACE_NVME_RW_DSTATE;
extern uint16_t _TRACE_NVME_CREATE_SQ_DSTATE;
extern uint16_t _TRACE_NVME_CREATE_CQ_DSTATE;
extern uint16_t _TRACE_NVME_DEL_SQ_DSTATE;
extern uint16_t _TRACE_NVME_DEL_CQ_DSTATE;
extern uint16_t _TRACE_NVME_IDENTIFY_CTRL_DSTATE;
extern uint16_t _TRACE_NVME_IDENTIFY_NS_DSTATE;
extern uint16_t _TRACE_NVME_IDENTIFY_NSLIST_DSTATE;
extern uint16_t _TRACE_NVME_GETFEAT_VWCACHE_DSTATE;
extern uint16_t _TRACE_NVME_GETFEAT_NUMQ_DSTATE;
extern uint16_t _TRACE_NVME_SETFEAT_NUMQ_DSTATE;
extern uint16_t _TRACE_NVME_MMIO_INTM_SET_DSTATE;
extern uint16_t _TRACE_NVME_MMIO_INTM_CLR_DSTATE;
extern uint16_t _TRACE_NVME_MMIO_CFG_DSTATE;
extern uint16_t _TRACE_NVME_MMIO_AQATTR_DSTATE;
extern uint16_t _TRACE_NVME_MMIO_ASQADDR_DSTATE;
extern uint16_t _TRACE_NVME_MMIO_ACQADDR_DSTATE;
extern uint16_t _TRACE_NVME_MMIO_ASQADDR_HI_DSTATE;
extern uint16_t _TRACE_NVME_MMIO_ACQADDR_HI_DSTATE;
extern uint16_t _TRACE_NVME_MMIO_START_SUCCESS_DSTATE;
extern uint16_t _TRACE_NVME_MMIO_STOPPED_DSTATE;
extern uint16_t _TRACE_NVME_MMIO_SHUTDOWN_SET_DSTATE;
extern uint16_t _TRACE_NVME_MMIO_SHUTDOWN_CLEARED_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_DMA_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_PRPLIST_ENT_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_PRP2_ALIGN_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_PRP2_MISSING_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_PRP_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_NS_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_OPC_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_ADMIN_OPC_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_LBA_RANGE_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_DEL_SQ_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_CREATE_SQ_CQID_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_CREATE_SQ_SQID_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_CREATE_SQ_SIZE_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_CREATE_SQ_ADDR_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_CREATE_SQ_QFLAGS_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_DEL_CQ_CQID_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_DEL_CQ_NOTEMPTY_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_CREATE_CQ_CQID_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_CREATE_CQ_SIZE_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_CREATE_CQ_ADDR_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_CREATE_CQ_VECTOR_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_CREATE_CQ_QFLAGS_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_IDENTIFY_CNS_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_GETFEAT_DSTATE;
extern uint16_t _TRACE_NVME_ERR_INVALID_SETFEAT_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_CQ_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_SQ_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_NBARASQ_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_NBARACQ_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_ASQ_MISALIGNED_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_ACQ_MISALIGNED_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_PAGE_TOO_SMALL_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_PAGE_TOO_LARGE_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_CQENT_TOO_SMALL_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_CQENT_TOO_LARGE_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_SQENT_TOO_SMALL_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_SQENT_TOO_LARGE_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_ASQENT_SZ_ZERO_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_ACQENT_SZ_ZERO_DSTATE;
extern uint16_t _TRACE_NVME_ERR_STARTFAIL_DSTATE;
extern uint16_t _TRACE_NVME_UB_MMIOWR_MISALIGNED32_DSTATE;
extern uint16_t _TRACE_NVME_UB_MMIOWR_TOOSMALL_DSTATE;
extern uint16_t _TRACE_NVME_UB_MMIOWR_INTMASK_WITH_MSIX_DSTATE;
extern uint16_t _TRACE_NVME_UB_MMIOWR_RO_CSTS_DSTATE;
extern uint16_t _TRACE_NVME_UB_MMIOWR_SSRESET_W1C_UNSUPPORTED_DSTATE;
extern uint16_t _TRACE_NVME_UB_MMIOWR_SSRESET_UNSUPPORTED_DSTATE;
extern uint16_t _TRACE_NVME_UB_MMIOWR_CMBLOC_RESERVED_DSTATE;
extern uint16_t _TRACE_NVME_UB_MMIOWR_CMBSZ_READONLY_DSTATE;
extern uint16_t _TRACE_NVME_UB_MMIOWR_INVALID_DSTATE;
extern uint16_t _TRACE_NVME_UB_MMIORD_MISALIGNED32_DSTATE;
extern uint16_t _TRACE_NVME_UB_MMIORD_TOOSMALL_DSTATE;
extern uint16_t _TRACE_NVME_UB_MMIORD_INVALID_OFS_DSTATE;
extern uint16_t _TRACE_NVME_UB_DB_WR_MISALIGNED_DSTATE;
extern uint16_t _TRACE_NVME_UB_DB_WR_INVALID_CQ_DSTATE;
extern uint16_t _TRACE_NVME_UB_DB_WR_INVALID_CQHEAD_DSTATE;
extern uint16_t _TRACE_NVME_UB_DB_WR_INVALID_SQ_DSTATE;
extern uint16_t _TRACE_NVME_UB_DB_WR_INVALID_SQTAIL_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_REALIZE_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_CONNECT_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_DISCONNECT_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_UNREALIZE_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_SIZE_DSTATE;
extern uint16_t _TRACE_XEN_DISK_REALIZE_DSTATE;
extern uint16_t _TRACE_XEN_DISK_UNREALIZE_DSTATE;
extern uint16_t _TRACE_XEN_CDROM_REALIZE_DSTATE;
extern uint16_t _TRACE_XEN_CDROM_UNREALIZE_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_BLOCKDEV_ADD_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_BLOCKDEV_DEL_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_DEVICE_CREATE_DSTATE;
extern uint16_t _TRACE_XEN_BLOCK_DEVICE_DESTROY_DSTATE;
#define TRACE_FDC_IOPORT_READ_ENABLED 1
#define TRACE_FDC_IOPORT_WRITE_ENABLED 1
#define TRACE_PFLASH_RESET_ENABLED 1
#define TRACE_PFLASH_READ_ENABLED 1
#define TRACE_PFLASH_WRITE_ENABLED 1
#define TRACE_PFLASH_TIMER_EXPIRED_ENABLED 1
#define TRACE_PFLASH_DATA_READ8_ENABLED 1
#define TRACE_PFLASH_DATA_READ16_ENABLED 1
#define TRACE_PFLASH_DATA_READ32_ENABLED 1
#define TRACE_PFLASH_DATA_WRITE_ENABLED 1
#define TRACE_PFLASH_MANUFACTURER_ID_ENABLED 1
#define TRACE_PFLASH_DEVICE_ID_ENABLED 1
#define TRACE_PFLASH_DEVICE_INFO_ENABLED 1
#define TRACE_VIRTIO_BLK_REQ_COMPLETE_ENABLED 1
#define TRACE_VIRTIO_BLK_RW_COMPLETE_ENABLED 1
#define TRACE_VIRTIO_BLK_HANDLE_WRITE_ENABLED 1
#define TRACE_VIRTIO_BLK_HANDLE_READ_ENABLED 1
#define TRACE_VIRTIO_BLK_SUBMIT_MULTIREQ_ENABLED 1
#define TRACE_HD_GEOMETRY_LCHS_GUESS_ENABLED 1
#define TRACE_HD_GEOMETRY_GUESS_ENABLED 1
#define TRACE_NVME_IRQ_MSIX_ENABLED 1
#define TRACE_NVME_IRQ_PIN_ENABLED 1
#define TRACE_NVME_IRQ_MASKED_ENABLED 1
#define TRACE_NVME_DMA_READ_ENABLED 1
#define TRACE_NVME_RW_ENABLED 1
#define TRACE_NVME_CREATE_SQ_ENABLED 1
#define TRACE_NVME_CREATE_CQ_ENABLED 1
#define TRACE_NVME_DEL_SQ_ENABLED 1
#define TRACE_NVME_DEL_CQ_ENABLED 1
#define TRACE_NVME_IDENTIFY_CTRL_ENABLED 1
#define TRACE_NVME_IDENTIFY_NS_ENABLED 1
#define TRACE_NVME_IDENTIFY_NSLIST_ENABLED 1
#define TRACE_NVME_GETFEAT_VWCACHE_ENABLED 1
#define TRACE_NVME_GETFEAT_NUMQ_ENABLED 1
#define TRACE_NVME_SETFEAT_NUMQ_ENABLED 1
#define TRACE_NVME_MMIO_INTM_SET_ENABLED 1
#define TRACE_NVME_MMIO_INTM_CLR_ENABLED 1
#define TRACE_NVME_MMIO_CFG_ENABLED 1
#define TRACE_NVME_MMIO_AQATTR_ENABLED 1
#define TRACE_NVME_MMIO_ASQADDR_ENABLED 1
#define TRACE_NVME_MMIO_ACQADDR_ENABLED 1
#define TRACE_NVME_MMIO_ASQADDR_HI_ENABLED 1
#define TRACE_NVME_MMIO_ACQADDR_HI_ENABLED 1
#define TRACE_NVME_MMIO_START_SUCCESS_ENABLED 1
#define TRACE_NVME_MMIO_STOPPED_ENABLED 1
#define TRACE_NVME_MMIO_SHUTDOWN_SET_ENABLED 1
#define TRACE_NVME_MMIO_SHUTDOWN_CLEARED_ENABLED 1
#define TRACE_NVME_ERR_INVALID_DMA_ENABLED 1
#define TRACE_NVME_ERR_INVALID_PRPLIST_ENT_ENABLED 1
#define TRACE_NVME_ERR_INVALID_PRP2_ALIGN_ENABLED 1
#define TRACE_NVME_ERR_INVALID_PRP2_MISSING_ENABLED 1
#define TRACE_NVME_ERR_INVALID_PRP_ENABLED 1
#define TRACE_NVME_ERR_INVALID_NS_ENABLED 1
#define TRACE_NVME_ERR_INVALID_OPC_ENABLED 1
#define TRACE_NVME_ERR_INVALID_ADMIN_OPC_ENABLED 1
#define TRACE_NVME_ERR_INVALID_LBA_RANGE_ENABLED 1
#define TRACE_NVME_ERR_INVALID_DEL_SQ_ENABLED 1
#define TRACE_NVME_ERR_INVALID_CREATE_SQ_CQID_ENABLED 1
#define TRACE_NVME_ERR_INVALID_CREATE_SQ_SQID_ENABLED 1
#define TRACE_NVME_ERR_INVALID_CREATE_SQ_SIZE_ENABLED 1
#define TRACE_NVME_ERR_INVALID_CREATE_SQ_ADDR_ENABLED 1
#define TRACE_NVME_ERR_INVALID_CREATE_SQ_QFLAGS_ENABLED 1
#define TRACE_NVME_ERR_INVALID_DEL_CQ_CQID_ENABLED 1
#define TRACE_NVME_ERR_INVALID_DEL_CQ_NOTEMPTY_ENABLED 1
#define TRACE_NVME_ERR_INVALID_CREATE_CQ_CQID_ENABLED 1
#define TRACE_NVME_ERR_INVALID_CREATE_CQ_SIZE_ENABLED 1
#define TRACE_NVME_ERR_INVALID_CREATE_CQ_ADDR_ENABLED 1
#define TRACE_NVME_ERR_INVALID_CREATE_CQ_VECTOR_ENABLED 1
#define TRACE_NVME_ERR_INVALID_CREATE_CQ_QFLAGS_ENABLED 1
#define TRACE_NVME_ERR_INVALID_IDENTIFY_CNS_ENABLED 1
#define TRACE_NVME_ERR_INVALID_GETFEAT_ENABLED 1
#define TRACE_NVME_ERR_INVALID_SETFEAT_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_CQ_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_SQ_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_NBARASQ_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_NBARACQ_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_ASQ_MISALIGNED_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_ACQ_MISALIGNED_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_PAGE_TOO_SMALL_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_PAGE_TOO_LARGE_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_CQENT_TOO_SMALL_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_CQENT_TOO_LARGE_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_SQENT_TOO_SMALL_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_SQENT_TOO_LARGE_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_ASQENT_SZ_ZERO_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_ACQENT_SZ_ZERO_ENABLED 1
#define TRACE_NVME_ERR_STARTFAIL_ENABLED 1
#define TRACE_NVME_UB_MMIOWR_MISALIGNED32_ENABLED 1
#define TRACE_NVME_UB_MMIOWR_TOOSMALL_ENABLED 1
#define TRACE_NVME_UB_MMIOWR_INTMASK_WITH_MSIX_ENABLED 1
#define TRACE_NVME_UB_MMIOWR_RO_CSTS_ENABLED 1
#define TRACE_NVME_UB_MMIOWR_SSRESET_W1C_UNSUPPORTED_ENABLED 1
#define TRACE_NVME_UB_MMIOWR_SSRESET_UNSUPPORTED_ENABLED 1
#define TRACE_NVME_UB_MMIOWR_CMBLOC_RESERVED_ENABLED 1
#define TRACE_NVME_UB_MMIOWR_CMBSZ_READONLY_ENABLED 1
#define TRACE_NVME_UB_MMIOWR_INVALID_ENABLED 1
#define TRACE_NVME_UB_MMIORD_MISALIGNED32_ENABLED 1
#define TRACE_NVME_UB_MMIORD_TOOSMALL_ENABLED 1
#define TRACE_NVME_UB_MMIORD_INVALID_OFS_ENABLED 1
#define TRACE_NVME_UB_DB_WR_MISALIGNED_ENABLED 1
#define TRACE_NVME_UB_DB_WR_INVALID_CQ_ENABLED 1
#define TRACE_NVME_UB_DB_WR_INVALID_CQHEAD_ENABLED 1
#define TRACE_NVME_UB_DB_WR_INVALID_SQ_ENABLED 1
#define TRACE_NVME_UB_DB_WR_INVALID_SQTAIL_ENABLED 1
#define TRACE_XEN_BLOCK_REALIZE_ENABLED 1
#define TRACE_XEN_BLOCK_CONNECT_ENABLED 1
#define TRACE_XEN_BLOCK_DISCONNECT_ENABLED 1
#define TRACE_XEN_BLOCK_UNREALIZE_ENABLED 1
#define TRACE_XEN_BLOCK_SIZE_ENABLED 1
#define TRACE_XEN_DISK_REALIZE_ENABLED 1
#define TRACE_XEN_DISK_UNREALIZE_ENABLED 1
#define TRACE_XEN_CDROM_REALIZE_ENABLED 1
#define TRACE_XEN_CDROM_UNREALIZE_ENABLED 1
#define TRACE_XEN_BLOCK_BLOCKDEV_ADD_ENABLED 1
#define TRACE_XEN_BLOCK_BLOCKDEV_DEL_ENABLED 1
#define TRACE_XEN_BLOCK_DEVICE_CREATE_ENABLED 1
#define TRACE_XEN_BLOCK_DEVICE_DESTROY_ENABLED 1
#include "qemu/log-for-trace.h"


#define TRACE_FDC_IOPORT_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_FDC_IOPORT_READ) || \
    false)

static inline void _nocheck__trace_fdc_ioport_read(uint8_t reg, uint8_t value)
{
    if (trace_event_get_state(TRACE_FDC_IOPORT_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:fdc_ioport_read " "read reg 0x%02x val 0x%02x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , reg, value);
    }
}

static inline void trace_fdc_ioport_read(uint8_t reg, uint8_t value)
{
    if (true) {
        _nocheck__trace_fdc_ioport_read(reg, value);
    }
}

#define TRACE_FDC_IOPORT_WRITE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_FDC_IOPORT_WRITE) || \
    false)

static inline void _nocheck__trace_fdc_ioport_write(uint8_t reg, uint8_t value)
{
    if (trace_event_get_state(TRACE_FDC_IOPORT_WRITE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:fdc_ioport_write " "write reg 0x%02x val 0x%02x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , reg, value);
    }
}

static inline void trace_fdc_ioport_write(uint8_t reg, uint8_t value)
{
    if (true) {
        _nocheck__trace_fdc_ioport_write(reg, value);
    }
}

#define TRACE_PFLASH_RESET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_RESET) || \
    false)

static inline void _nocheck__trace_pflash_reset(void)
{
    if (trace_event_get_state(TRACE_PFLASH_RESET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_reset " "reset" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_pflash_reset(void)
{
    if (true) {
        _nocheck__trace_pflash_reset();
    }
}

#define TRACE_PFLASH_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_READ) || \
    false)

static inline void _nocheck__trace_pflash_read(uint64_t offset, uint8_t cmd, int width, uint8_t wcycle)
{
    if (trace_event_get_state(TRACE_PFLASH_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_read " "offset:0x%04"PRIx64" cmd:0x%02x width:%d wcycle:%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, cmd, width, wcycle);
    }
}

static inline void trace_pflash_read(uint64_t offset, uint8_t cmd, int width, uint8_t wcycle)
{
    if (true) {
        _nocheck__trace_pflash_read(offset, cmd, width, wcycle);
    }
}

#define TRACE_PFLASH_WRITE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_WRITE) || \
    false)

static inline void _nocheck__trace_pflash_write(uint64_t offset, uint32_t value, int width, uint8_t wcycle)
{
    if (trace_event_get_state(TRACE_PFLASH_WRITE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_write " "offset:0x%04"PRIx64" value:0x%03x width:%d wcycle:%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, value, width, wcycle);
    }
}

static inline void trace_pflash_write(uint64_t offset, uint32_t value, int width, uint8_t wcycle)
{
    if (true) {
        _nocheck__trace_pflash_write(offset, value, width, wcycle);
    }
}

#define TRACE_PFLASH_TIMER_EXPIRED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_TIMER_EXPIRED) || \
    false)

static inline void _nocheck__trace_pflash_timer_expired(uint8_t cmd)
{
    if (trace_event_get_state(TRACE_PFLASH_TIMER_EXPIRED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_timer_expired " "command 0x%02x done" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cmd);
    }
}

static inline void trace_pflash_timer_expired(uint8_t cmd)
{
    if (true) {
        _nocheck__trace_pflash_timer_expired(cmd);
    }
}

#define TRACE_PFLASH_DATA_READ8_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_DATA_READ8) || \
    false)

static inline void _nocheck__trace_pflash_data_read8(uint64_t offset, uint32_t value)
{
    if (trace_event_get_state(TRACE_PFLASH_DATA_READ8) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_data_read8 " "data offset:0x%04"PRIx64" value:0x%02x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, value);
    }
}

static inline void trace_pflash_data_read8(uint64_t offset, uint32_t value)
{
    if (true) {
        _nocheck__trace_pflash_data_read8(offset, value);
    }
}

#define TRACE_PFLASH_DATA_READ16_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_DATA_READ16) || \
    false)

static inline void _nocheck__trace_pflash_data_read16(uint64_t offset, uint32_t value)
{
    if (trace_event_get_state(TRACE_PFLASH_DATA_READ16) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_data_read16 " "data offset:0x%04"PRIx64" value:0x%04x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, value);
    }
}

static inline void trace_pflash_data_read16(uint64_t offset, uint32_t value)
{
    if (true) {
        _nocheck__trace_pflash_data_read16(offset, value);
    }
}

#define TRACE_PFLASH_DATA_READ32_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_DATA_READ32) || \
    false)

static inline void _nocheck__trace_pflash_data_read32(uint64_t offset, uint32_t value)
{
    if (trace_event_get_state(TRACE_PFLASH_DATA_READ32) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_data_read32 " "data offset:0x%04"PRIx64" value:0x%08x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, value);
    }
}

static inline void trace_pflash_data_read32(uint64_t offset, uint32_t value)
{
    if (true) {
        _nocheck__trace_pflash_data_read32(offset, value);
    }
}

#define TRACE_PFLASH_DATA_WRITE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_DATA_WRITE) || \
    false)

static inline void _nocheck__trace_pflash_data_write(uint64_t offset, uint32_t value, int width, uint64_t counter)
{
    if (trace_event_get_state(TRACE_PFLASH_DATA_WRITE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_data_write " "data offset:0x%04"PRIx64" value:0x%08x width:%d counter:0x%016"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, value, width, counter);
    }
}

static inline void trace_pflash_data_write(uint64_t offset, uint32_t value, int width, uint64_t counter)
{
    if (true) {
        _nocheck__trace_pflash_data_write(offset, value, width, counter);
    }
}

#define TRACE_PFLASH_MANUFACTURER_ID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_MANUFACTURER_ID) || \
    false)

static inline void _nocheck__trace_pflash_manufacturer_id(uint16_t id)
{
    if (trace_event_get_state(TRACE_PFLASH_MANUFACTURER_ID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_manufacturer_id " "Read Manufacturer ID: 0x%04x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , id);
    }
}

static inline void trace_pflash_manufacturer_id(uint16_t id)
{
    if (true) {
        _nocheck__trace_pflash_manufacturer_id(id);
    }
}

#define TRACE_PFLASH_DEVICE_ID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_DEVICE_ID) || \
    false)

static inline void _nocheck__trace_pflash_device_id(uint16_t id)
{
    if (trace_event_get_state(TRACE_PFLASH_DEVICE_ID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_device_id " "Read Device ID: 0x%04x" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , id);
    }
}

static inline void trace_pflash_device_id(uint16_t id)
{
    if (true) {
        _nocheck__trace_pflash_device_id(id);
    }
}

#define TRACE_PFLASH_DEVICE_INFO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_PFLASH_DEVICE_INFO) || \
    false)

static inline void _nocheck__trace_pflash_device_info(uint64_t offset)
{
    if (trace_event_get_state(TRACE_PFLASH_DEVICE_INFO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:pflash_device_info " "Read Device Information offset:0x%04"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_pflash_device_info(uint64_t offset)
{
    if (true) {
        _nocheck__trace_pflash_device_info(offset);
    }
}

#define TRACE_VIRTIO_BLK_REQ_COMPLETE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BLK_REQ_COMPLETE) || \
    false)

static inline void _nocheck__trace_virtio_blk_req_complete(void * vdev, void * req, int status)
{
    if (trace_event_get_state(TRACE_VIRTIO_BLK_REQ_COMPLETE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_blk_req_complete " "vdev %p req %p status %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, req, status);
    }
}

static inline void trace_virtio_blk_req_complete(void * vdev, void * req, int status)
{
    if (true) {
        _nocheck__trace_virtio_blk_req_complete(vdev, req, status);
    }
}

#define TRACE_VIRTIO_BLK_RW_COMPLETE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BLK_RW_COMPLETE) || \
    false)

static inline void _nocheck__trace_virtio_blk_rw_complete(void * vdev, void * req, int ret)
{
    if (trace_event_get_state(TRACE_VIRTIO_BLK_RW_COMPLETE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_blk_rw_complete " "vdev %p req %p ret %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, req, ret);
    }
}

static inline void trace_virtio_blk_rw_complete(void * vdev, void * req, int ret)
{
    if (true) {
        _nocheck__trace_virtio_blk_rw_complete(vdev, req, ret);
    }
}

#define TRACE_VIRTIO_BLK_HANDLE_WRITE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BLK_HANDLE_WRITE) || \
    false)

static inline void _nocheck__trace_virtio_blk_handle_write(void * vdev, void * req, uint64_t sector, size_t nsectors)
{
    if (trace_event_get_state(TRACE_VIRTIO_BLK_HANDLE_WRITE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_blk_handle_write " "vdev %p req %p sector %"PRIu64" nsectors %zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, req, sector, nsectors);
    }
}

static inline void trace_virtio_blk_handle_write(void * vdev, void * req, uint64_t sector, size_t nsectors)
{
    if (true) {
        _nocheck__trace_virtio_blk_handle_write(vdev, req, sector, nsectors);
    }
}

#define TRACE_VIRTIO_BLK_HANDLE_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BLK_HANDLE_READ) || \
    false)

static inline void _nocheck__trace_virtio_blk_handle_read(void * vdev, void * req, uint64_t sector, size_t nsectors)
{
    if (trace_event_get_state(TRACE_VIRTIO_BLK_HANDLE_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_blk_handle_read " "vdev %p req %p sector %"PRIu64" nsectors %zu" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, req, sector, nsectors);
    }
}

static inline void trace_virtio_blk_handle_read(void * vdev, void * req, uint64_t sector, size_t nsectors)
{
    if (true) {
        _nocheck__trace_virtio_blk_handle_read(vdev, req, sector, nsectors);
    }
}

#define TRACE_VIRTIO_BLK_SUBMIT_MULTIREQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BLK_SUBMIT_MULTIREQ) || \
    false)

static inline void _nocheck__trace_virtio_blk_submit_multireq(void * vdev, void * mrb, int start, int num_reqs, uint64_t offset, size_t size, bool is_write)
{
    if (trace_event_get_state(TRACE_VIRTIO_BLK_SUBMIT_MULTIREQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_blk_submit_multireq " "vdev %p mrb %p start %d num_reqs %d offset %"PRIu64" size %zu is_write %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, mrb, start, num_reqs, offset, size, is_write);
    }
}

static inline void trace_virtio_blk_submit_multireq(void * vdev, void * mrb, int start, int num_reqs, uint64_t offset, size_t size, bool is_write)
{
    if (true) {
        _nocheck__trace_virtio_blk_submit_multireq(vdev, mrb, start, num_reqs, offset, size, is_write);
    }
}

#define TRACE_HD_GEOMETRY_LCHS_GUESS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_HD_GEOMETRY_LCHS_GUESS) || \
    false)

static inline void _nocheck__trace_hd_geometry_lchs_guess(void * blk, int cyls, int heads, int secs)
{
    if (trace_event_get_state(TRACE_HD_GEOMETRY_LCHS_GUESS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:hd_geometry_lchs_guess " "blk %p LCHS %d %d %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , blk, cyls, heads, secs);
    }
}

static inline void trace_hd_geometry_lchs_guess(void * blk, int cyls, int heads, int secs)
{
    if (true) {
        _nocheck__trace_hd_geometry_lchs_guess(blk, cyls, heads, secs);
    }
}

#define TRACE_HD_GEOMETRY_GUESS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_HD_GEOMETRY_GUESS) || \
    false)

static inline void _nocheck__trace_hd_geometry_guess(void * blk, uint32_t cyls, uint32_t heads, uint32_t secs, int trans)
{
    if (trace_event_get_state(TRACE_HD_GEOMETRY_GUESS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:hd_geometry_guess " "blk %p CHS %u %u %u trans %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , blk, cyls, heads, secs, trans);
    }
}

static inline void trace_hd_geometry_guess(void * blk, uint32_t cyls, uint32_t heads, uint32_t secs, int trans)
{
    if (true) {
        _nocheck__trace_hd_geometry_guess(blk, cyls, heads, secs, trans);
    }
}

#define TRACE_NVME_IRQ_MSIX_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_IRQ_MSIX) || \
    false)

static inline void _nocheck__trace_nvme_irq_msix(uint32_t vector)
{
    if (trace_event_get_state(TRACE_NVME_IRQ_MSIX) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_irq_msix " "raising MSI-X IRQ vector %u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vector);
    }
}

static inline void trace_nvme_irq_msix(uint32_t vector)
{
    if (true) {
        _nocheck__trace_nvme_irq_msix(vector);
    }
}

#define TRACE_NVME_IRQ_PIN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_IRQ_PIN) || \
    false)

static inline void _nocheck__trace_nvme_irq_pin(void)
{
    if (trace_event_get_state(TRACE_NVME_IRQ_PIN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_irq_pin " "pulsing IRQ pin" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_irq_pin(void)
{
    if (true) {
        _nocheck__trace_nvme_irq_pin();
    }
}

#define TRACE_NVME_IRQ_MASKED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_IRQ_MASKED) || \
    false)

static inline void _nocheck__trace_nvme_irq_masked(void)
{
    if (trace_event_get_state(TRACE_NVME_IRQ_MASKED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_irq_masked " "IRQ is masked" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_irq_masked(void)
{
    if (true) {
        _nocheck__trace_nvme_irq_masked();
    }
}

#define TRACE_NVME_DMA_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_DMA_READ) || \
    false)

static inline void _nocheck__trace_nvme_dma_read(uint64_t prp1, uint64_t prp2)
{
    if (trace_event_get_state(TRACE_NVME_DMA_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_dma_read " "DMA read, prp1=0x%"PRIx64" prp2=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , prp1, prp2);
    }
}

static inline void trace_nvme_dma_read(uint64_t prp1, uint64_t prp2)
{
    if (true) {
        _nocheck__trace_nvme_dma_read(prp1, prp2);
    }
}

#define TRACE_NVME_RW_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_RW) || \
    false)

static inline void _nocheck__trace_nvme_rw(const char * verb, uint32_t blk_count, uint64_t byte_count, uint64_t lba)
{
    if (trace_event_get_state(TRACE_NVME_RW) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_rw " "%s %"PRIu32" blocks (%"PRIu64" bytes) from LBA %"PRIu64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , verb, blk_count, byte_count, lba);
    }
}

static inline void trace_nvme_rw(const char * verb, uint32_t blk_count, uint64_t byte_count, uint64_t lba)
{
    if (true) {
        _nocheck__trace_nvme_rw(verb, blk_count, byte_count, lba);
    }
}

#define TRACE_NVME_CREATE_SQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_CREATE_SQ) || \
    false)

static inline void _nocheck__trace_nvme_create_sq(uint64_t addr, uint16_t sqid, uint16_t cqid, uint16_t qsize, uint16_t qflags)
{
    if (trace_event_get_state(TRACE_NVME_CREATE_SQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_create_sq " "create submission queue, addr=0x%"PRIx64", sqid=%"PRIu16", cqid=%"PRIu16", qsize=%"PRIu16", qflags=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr, sqid, cqid, qsize, qflags);
    }
}

static inline void trace_nvme_create_sq(uint64_t addr, uint16_t sqid, uint16_t cqid, uint16_t qsize, uint16_t qflags)
{
    if (true) {
        _nocheck__trace_nvme_create_sq(addr, sqid, cqid, qsize, qflags);
    }
}

#define TRACE_NVME_CREATE_CQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_CREATE_CQ) || \
    false)

static inline void _nocheck__trace_nvme_create_cq(uint64_t addr, uint16_t cqid, uint16_t vector, uint16_t size, uint16_t qflags, int ien)
{
    if (trace_event_get_state(TRACE_NVME_CREATE_CQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_create_cq " "create completion queue, addr=0x%"PRIx64", cqid=%"PRIu16", vector=%"PRIu16", qsize=%"PRIu16", qflags=%"PRIu16", ien=%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr, cqid, vector, size, qflags, ien);
    }
}

static inline void trace_nvme_create_cq(uint64_t addr, uint16_t cqid, uint16_t vector, uint16_t size, uint16_t qflags, int ien)
{
    if (true) {
        _nocheck__trace_nvme_create_cq(addr, cqid, vector, size, qflags, ien);
    }
}

#define TRACE_NVME_DEL_SQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_DEL_SQ) || \
    false)

static inline void _nocheck__trace_nvme_del_sq(uint16_t qid)
{
    if (trace_event_get_state(TRACE_NVME_DEL_SQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_del_sq " "deleting submission queue sqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qid);
    }
}

static inline void trace_nvme_del_sq(uint16_t qid)
{
    if (true) {
        _nocheck__trace_nvme_del_sq(qid);
    }
}

#define TRACE_NVME_DEL_CQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_DEL_CQ) || \
    false)

static inline void _nocheck__trace_nvme_del_cq(uint16_t cqid)
{
    if (trace_event_get_state(TRACE_NVME_DEL_CQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_del_cq " "deleted completion queue, sqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cqid);
    }
}

static inline void trace_nvme_del_cq(uint16_t cqid)
{
    if (true) {
        _nocheck__trace_nvme_del_cq(cqid);
    }
}

#define TRACE_NVME_IDENTIFY_CTRL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_IDENTIFY_CTRL) || \
    false)

static inline void _nocheck__trace_nvme_identify_ctrl(void)
{
    if (trace_event_get_state(TRACE_NVME_IDENTIFY_CTRL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_identify_ctrl " "identify controller" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_identify_ctrl(void)
{
    if (true) {
        _nocheck__trace_nvme_identify_ctrl();
    }
}

#define TRACE_NVME_IDENTIFY_NS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_IDENTIFY_NS) || \
    false)

static inline void _nocheck__trace_nvme_identify_ns(uint16_t ns)
{
    if (trace_event_get_state(TRACE_NVME_IDENTIFY_NS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_identify_ns " "identify namespace, nsid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ns);
    }
}

static inline void trace_nvme_identify_ns(uint16_t ns)
{
    if (true) {
        _nocheck__trace_nvme_identify_ns(ns);
    }
}

#define TRACE_NVME_IDENTIFY_NSLIST_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_IDENTIFY_NSLIST) || \
    false)

static inline void _nocheck__trace_nvme_identify_nslist(uint16_t ns)
{
    if (trace_event_get_state(TRACE_NVME_IDENTIFY_NSLIST) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_identify_nslist " "identify namespace list, nsid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ns);
    }
}

static inline void trace_nvme_identify_nslist(uint16_t ns)
{
    if (true) {
        _nocheck__trace_nvme_identify_nslist(ns);
    }
}

#define TRACE_NVME_GETFEAT_VWCACHE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_GETFEAT_VWCACHE) || \
    false)

static inline void _nocheck__trace_nvme_getfeat_vwcache(const char* result)
{
    if (trace_event_get_state(TRACE_NVME_GETFEAT_VWCACHE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_getfeat_vwcache " "get feature volatile write cache, result=%s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , result);
    }
}

static inline void trace_nvme_getfeat_vwcache(const char* result)
{
    if (true) {
        _nocheck__trace_nvme_getfeat_vwcache(result);
    }
}

#define TRACE_NVME_GETFEAT_NUMQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_GETFEAT_NUMQ) || \
    false)

static inline void _nocheck__trace_nvme_getfeat_numq(int result)
{
    if (trace_event_get_state(TRACE_NVME_GETFEAT_NUMQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_getfeat_numq " "get feature number of queues, result=%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , result);
    }
}

static inline void trace_nvme_getfeat_numq(int result)
{
    if (true) {
        _nocheck__trace_nvme_getfeat_numq(result);
    }
}

#define TRACE_NVME_SETFEAT_NUMQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_SETFEAT_NUMQ) || \
    false)

static inline void _nocheck__trace_nvme_setfeat_numq(int reqcq, int reqsq, int gotcq, int gotsq)
{
    if (trace_event_get_state(TRACE_NVME_SETFEAT_NUMQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_setfeat_numq " "requested cq_count=%d sq_count=%d, responding with cq_count=%d sq_count=%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , reqcq, reqsq, gotcq, gotsq);
    }
}

static inline void trace_nvme_setfeat_numq(int reqcq, int reqsq, int gotcq, int gotsq)
{
    if (true) {
        _nocheck__trace_nvme_setfeat_numq(reqcq, reqsq, gotcq, gotsq);
    }
}

#define TRACE_NVME_MMIO_INTM_SET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_MMIO_INTM_SET) || \
    false)

static inline void _nocheck__trace_nvme_mmio_intm_set(uint64_t data, uint64_t new_mask)
{
    if (trace_event_get_state(TRACE_NVME_MMIO_INTM_SET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_mmio_intm_set " "wrote MMIO, interrupt mask set, data=0x%"PRIx64", new_mask=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data, new_mask);
    }
}

static inline void trace_nvme_mmio_intm_set(uint64_t data, uint64_t new_mask)
{
    if (true) {
        _nocheck__trace_nvme_mmio_intm_set(data, new_mask);
    }
}

#define TRACE_NVME_MMIO_INTM_CLR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_MMIO_INTM_CLR) || \
    false)

static inline void _nocheck__trace_nvme_mmio_intm_clr(uint64_t data, uint64_t new_mask)
{
    if (trace_event_get_state(TRACE_NVME_MMIO_INTM_CLR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_mmio_intm_clr " "wrote MMIO, interrupt mask clr, data=0x%"PRIx64", new_mask=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data, new_mask);
    }
}

static inline void trace_nvme_mmio_intm_clr(uint64_t data, uint64_t new_mask)
{
    if (true) {
        _nocheck__trace_nvme_mmio_intm_clr(data, new_mask);
    }
}

#define TRACE_NVME_MMIO_CFG_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_MMIO_CFG) || \
    false)

static inline void _nocheck__trace_nvme_mmio_cfg(uint64_t data)
{
    if (trace_event_get_state(TRACE_NVME_MMIO_CFG) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_mmio_cfg " "wrote MMIO, config controller config=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data);
    }
}

static inline void trace_nvme_mmio_cfg(uint64_t data)
{
    if (true) {
        _nocheck__trace_nvme_mmio_cfg(data);
    }
}

#define TRACE_NVME_MMIO_AQATTR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_MMIO_AQATTR) || \
    false)

static inline void _nocheck__trace_nvme_mmio_aqattr(uint64_t data)
{
    if (trace_event_get_state(TRACE_NVME_MMIO_AQATTR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_mmio_aqattr " "wrote MMIO, admin queue attributes=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data);
    }
}

static inline void trace_nvme_mmio_aqattr(uint64_t data)
{
    if (true) {
        _nocheck__trace_nvme_mmio_aqattr(data);
    }
}

#define TRACE_NVME_MMIO_ASQADDR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_MMIO_ASQADDR) || \
    false)

static inline void _nocheck__trace_nvme_mmio_asqaddr(uint64_t data)
{
    if (trace_event_get_state(TRACE_NVME_MMIO_ASQADDR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_mmio_asqaddr " "wrote MMIO, admin submission queue address=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data);
    }
}

static inline void trace_nvme_mmio_asqaddr(uint64_t data)
{
    if (true) {
        _nocheck__trace_nvme_mmio_asqaddr(data);
    }
}

#define TRACE_NVME_MMIO_ACQADDR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_MMIO_ACQADDR) || \
    false)

static inline void _nocheck__trace_nvme_mmio_acqaddr(uint64_t data)
{
    if (trace_event_get_state(TRACE_NVME_MMIO_ACQADDR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_mmio_acqaddr " "wrote MMIO, admin completion queue address=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data);
    }
}

static inline void trace_nvme_mmio_acqaddr(uint64_t data)
{
    if (true) {
        _nocheck__trace_nvme_mmio_acqaddr(data);
    }
}

#define TRACE_NVME_MMIO_ASQADDR_HI_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_MMIO_ASQADDR_HI) || \
    false)

static inline void _nocheck__trace_nvme_mmio_asqaddr_hi(uint64_t data, uint64_t new_addr)
{
    if (trace_event_get_state(TRACE_NVME_MMIO_ASQADDR_HI) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_mmio_asqaddr_hi " "wrote MMIO, admin submission queue high half=0x%"PRIx64", new_address=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data, new_addr);
    }
}

static inline void trace_nvme_mmio_asqaddr_hi(uint64_t data, uint64_t new_addr)
{
    if (true) {
        _nocheck__trace_nvme_mmio_asqaddr_hi(data, new_addr);
    }
}

#define TRACE_NVME_MMIO_ACQADDR_HI_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_MMIO_ACQADDR_HI) || \
    false)

static inline void _nocheck__trace_nvme_mmio_acqaddr_hi(uint64_t data, uint64_t new_addr)
{
    if (trace_event_get_state(TRACE_NVME_MMIO_ACQADDR_HI) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_mmio_acqaddr_hi " "wrote MMIO, admin completion queue high half=0x%"PRIx64", new_address=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , data, new_addr);
    }
}

static inline void trace_nvme_mmio_acqaddr_hi(uint64_t data, uint64_t new_addr)
{
    if (true) {
        _nocheck__trace_nvme_mmio_acqaddr_hi(data, new_addr);
    }
}

#define TRACE_NVME_MMIO_START_SUCCESS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_MMIO_START_SUCCESS) || \
    false)

static inline void _nocheck__trace_nvme_mmio_start_success(void)
{
    if (trace_event_get_state(TRACE_NVME_MMIO_START_SUCCESS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_mmio_start_success " "setting controller enable bit succeeded" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_mmio_start_success(void)
{
    if (true) {
        _nocheck__trace_nvme_mmio_start_success();
    }
}

#define TRACE_NVME_MMIO_STOPPED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_MMIO_STOPPED) || \
    false)

static inline void _nocheck__trace_nvme_mmio_stopped(void)
{
    if (trace_event_get_state(TRACE_NVME_MMIO_STOPPED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_mmio_stopped " "cleared controller enable bit" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_mmio_stopped(void)
{
    if (true) {
        _nocheck__trace_nvme_mmio_stopped();
    }
}

#define TRACE_NVME_MMIO_SHUTDOWN_SET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_MMIO_SHUTDOWN_SET) || \
    false)

static inline void _nocheck__trace_nvme_mmio_shutdown_set(void)
{
    if (trace_event_get_state(TRACE_NVME_MMIO_SHUTDOWN_SET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_mmio_shutdown_set " "shutdown bit set" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_mmio_shutdown_set(void)
{
    if (true) {
        _nocheck__trace_nvme_mmio_shutdown_set();
    }
}

#define TRACE_NVME_MMIO_SHUTDOWN_CLEARED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_MMIO_SHUTDOWN_CLEARED) || \
    false)

static inline void _nocheck__trace_nvme_mmio_shutdown_cleared(void)
{
    if (trace_event_get_state(TRACE_NVME_MMIO_SHUTDOWN_CLEARED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_mmio_shutdown_cleared " "shutdown bit cleared" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_mmio_shutdown_cleared(void)
{
    if (true) {
        _nocheck__trace_nvme_mmio_shutdown_cleared();
    }
}

#define TRACE_NVME_ERR_INVALID_DMA_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_DMA) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_dma(void)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_DMA) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_dma " "PRP/SGL is too small for transfer size" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_err_invalid_dma(void)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_dma();
    }
}

#define TRACE_NVME_ERR_INVALID_PRPLIST_ENT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_PRPLIST_ENT) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_prplist_ent(uint64_t prplist)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_PRPLIST_ENT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_prplist_ent " "PRP list entry is null or not page aligned: 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , prplist);
    }
}

static inline void trace_nvme_err_invalid_prplist_ent(uint64_t prplist)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_prplist_ent(prplist);
    }
}

#define TRACE_NVME_ERR_INVALID_PRP2_ALIGN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_PRP2_ALIGN) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_prp2_align(uint64_t prp2)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_PRP2_ALIGN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_prp2_align " "PRP2 is not page aligned: 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , prp2);
    }
}

static inline void trace_nvme_err_invalid_prp2_align(uint64_t prp2)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_prp2_align(prp2);
    }
}

#define TRACE_NVME_ERR_INVALID_PRP2_MISSING_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_PRP2_MISSING) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_prp2_missing(void)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_PRP2_MISSING) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_prp2_missing " "PRP2 is null and more data to be transferred" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_err_invalid_prp2_missing(void)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_prp2_missing();
    }
}

#define TRACE_NVME_ERR_INVALID_PRP_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_PRP) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_prp(void)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_PRP) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_prp " "invalid PRP" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_err_invalid_prp(void)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_prp();
    }
}

#define TRACE_NVME_ERR_INVALID_NS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_NS) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_ns(uint32_t ns, uint32_t limit)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_NS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_ns " "invalid namespace %u not within 1-%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , ns, limit);
    }
}

static inline void trace_nvme_err_invalid_ns(uint32_t ns, uint32_t limit)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_ns(ns, limit);
    }
}

#define TRACE_NVME_ERR_INVALID_OPC_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_OPC) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_opc(uint8_t opc)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_OPC) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_opc " "invalid opcode 0x%"PRIx8"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , opc);
    }
}

static inline void trace_nvme_err_invalid_opc(uint8_t opc)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_opc(opc);
    }
}

#define TRACE_NVME_ERR_INVALID_ADMIN_OPC_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_ADMIN_OPC) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_admin_opc(uint8_t opc)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_ADMIN_OPC) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_admin_opc " "invalid admin opcode 0x%"PRIx8"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , opc);
    }
}

static inline void trace_nvme_err_invalid_admin_opc(uint8_t opc)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_admin_opc(opc);
    }
}

#define TRACE_NVME_ERR_INVALID_LBA_RANGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_LBA_RANGE) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_lba_range(uint64_t start, uint64_t len, uint64_t limit)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_LBA_RANGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_lba_range " "Invalid LBA start=%"PRIu64" len=%"PRIu64" limit=%"PRIu64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , start, len, limit);
    }
}

static inline void trace_nvme_err_invalid_lba_range(uint64_t start, uint64_t len, uint64_t limit)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_lba_range(start, len, limit);
    }
}

#define TRACE_NVME_ERR_INVALID_DEL_SQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_DEL_SQ) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_del_sq(uint16_t qid)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_DEL_SQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_del_sq " "invalid submission queue deletion, sid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qid);
    }
}

static inline void trace_nvme_err_invalid_del_sq(uint16_t qid)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_del_sq(qid);
    }
}

#define TRACE_NVME_ERR_INVALID_CREATE_SQ_CQID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_CREATE_SQ_CQID) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_create_sq_cqid(uint16_t cqid)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_CREATE_SQ_CQID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_create_sq_cqid " "failed creating submission queue, invalid cqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cqid);
    }
}

static inline void trace_nvme_err_invalid_create_sq_cqid(uint16_t cqid)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_create_sq_cqid(cqid);
    }
}

#define TRACE_NVME_ERR_INVALID_CREATE_SQ_SQID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_CREATE_SQ_SQID) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_create_sq_sqid(uint16_t sqid)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_CREATE_SQ_SQID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_create_sq_sqid " "failed creating submission queue, invalid sqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , sqid);
    }
}

static inline void trace_nvme_err_invalid_create_sq_sqid(uint16_t sqid)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_create_sq_sqid(sqid);
    }
}

#define TRACE_NVME_ERR_INVALID_CREATE_SQ_SIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_CREATE_SQ_SIZE) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_create_sq_size(uint16_t qsize)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_CREATE_SQ_SIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_create_sq_size " "failed creating submission queue, invalid qsize=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qsize);
    }
}

static inline void trace_nvme_err_invalid_create_sq_size(uint16_t qsize)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_create_sq_size(qsize);
    }
}

#define TRACE_NVME_ERR_INVALID_CREATE_SQ_ADDR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_CREATE_SQ_ADDR) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_create_sq_addr(uint64_t addr)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_CREATE_SQ_ADDR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_create_sq_addr " "failed creating submission queue, addr=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr);
    }
}

static inline void trace_nvme_err_invalid_create_sq_addr(uint64_t addr)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_create_sq_addr(addr);
    }
}

#define TRACE_NVME_ERR_INVALID_CREATE_SQ_QFLAGS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_CREATE_SQ_QFLAGS) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_create_sq_qflags(uint16_t qflags)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_CREATE_SQ_QFLAGS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_create_sq_qflags " "failed creating submission queue, qflags=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qflags);
    }
}

static inline void trace_nvme_err_invalid_create_sq_qflags(uint16_t qflags)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_create_sq_qflags(qflags);
    }
}

#define TRACE_NVME_ERR_INVALID_DEL_CQ_CQID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_DEL_CQ_CQID) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_del_cq_cqid(uint16_t cqid)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_DEL_CQ_CQID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_del_cq_cqid " "failed deleting completion queue, cqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cqid);
    }
}

static inline void trace_nvme_err_invalid_del_cq_cqid(uint16_t cqid)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_del_cq_cqid(cqid);
    }
}

#define TRACE_NVME_ERR_INVALID_DEL_CQ_NOTEMPTY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_DEL_CQ_NOTEMPTY) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_del_cq_notempty(uint16_t cqid)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_DEL_CQ_NOTEMPTY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_del_cq_notempty " "failed deleting completion queue, it is not empty, cqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cqid);
    }
}

static inline void trace_nvme_err_invalid_del_cq_notempty(uint16_t cqid)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_del_cq_notempty(cqid);
    }
}

#define TRACE_NVME_ERR_INVALID_CREATE_CQ_CQID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_CREATE_CQ_CQID) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_create_cq_cqid(uint16_t cqid)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_CREATE_CQ_CQID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_create_cq_cqid " "failed creating completion queue, cqid=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cqid);
    }
}

static inline void trace_nvme_err_invalid_create_cq_cqid(uint16_t cqid)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_create_cq_cqid(cqid);
    }
}

#define TRACE_NVME_ERR_INVALID_CREATE_CQ_SIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_CREATE_CQ_SIZE) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_create_cq_size(uint16_t size)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_CREATE_CQ_SIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_create_cq_size " "failed creating completion queue, size=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , size);
    }
}

static inline void trace_nvme_err_invalid_create_cq_size(uint16_t size)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_create_cq_size(size);
    }
}

#define TRACE_NVME_ERR_INVALID_CREATE_CQ_ADDR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_CREATE_CQ_ADDR) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_create_cq_addr(uint64_t addr)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_CREATE_CQ_ADDR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_create_cq_addr " "failed creating completion queue, addr=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr);
    }
}

static inline void trace_nvme_err_invalid_create_cq_addr(uint64_t addr)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_create_cq_addr(addr);
    }
}

#define TRACE_NVME_ERR_INVALID_CREATE_CQ_VECTOR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_CREATE_CQ_VECTOR) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_create_cq_vector(uint16_t vector)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_CREATE_CQ_VECTOR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_create_cq_vector " "failed creating completion queue, vector=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vector);
    }
}

static inline void trace_nvme_err_invalid_create_cq_vector(uint16_t vector)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_create_cq_vector(vector);
    }
}

#define TRACE_NVME_ERR_INVALID_CREATE_CQ_QFLAGS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_CREATE_CQ_QFLAGS) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_create_cq_qflags(uint16_t qflags)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_CREATE_CQ_QFLAGS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_create_cq_qflags " "failed creating completion queue, qflags=%"PRIu16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qflags);
    }
}

static inline void trace_nvme_err_invalid_create_cq_qflags(uint16_t qflags)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_create_cq_qflags(qflags);
    }
}

#define TRACE_NVME_ERR_INVALID_IDENTIFY_CNS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_IDENTIFY_CNS) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_identify_cns(uint16_t cns)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_IDENTIFY_CNS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_identify_cns " "identify, invalid cns=0x%"PRIx16"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , cns);
    }
}

static inline void trace_nvme_err_invalid_identify_cns(uint16_t cns)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_identify_cns(cns);
    }
}

#define TRACE_NVME_ERR_INVALID_GETFEAT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_GETFEAT) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_getfeat(int dw10)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_GETFEAT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_getfeat " "invalid get features, dw10=0x%"PRIx32"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , dw10);
    }
}

static inline void trace_nvme_err_invalid_getfeat(int dw10)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_getfeat(dw10);
    }
}

#define TRACE_NVME_ERR_INVALID_SETFEAT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_INVALID_SETFEAT) || \
    false)

static inline void _nocheck__trace_nvme_err_invalid_setfeat(uint32_t dw10)
{
    if (trace_event_get_state(TRACE_NVME_ERR_INVALID_SETFEAT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_invalid_setfeat " "invalid set features, dw10=0x%"PRIx32"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , dw10);
    }
}

static inline void trace_nvme_err_invalid_setfeat(uint32_t dw10)
{
    if (true) {
        _nocheck__trace_nvme_err_invalid_setfeat(dw10);
    }
}

#define TRACE_NVME_ERR_STARTFAIL_CQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_CQ) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_cq(void)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_CQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_cq " "nvme_start_ctrl failed because there are non-admin completion queues" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_err_startfail_cq(void)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_cq();
    }
}

#define TRACE_NVME_ERR_STARTFAIL_SQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_SQ) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_sq(void)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_SQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_sq " "nvme_start_ctrl failed because there are non-admin submission queues" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_err_startfail_sq(void)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_sq();
    }
}

#define TRACE_NVME_ERR_STARTFAIL_NBARASQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_NBARASQ) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_nbarasq(void)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_NBARASQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_nbarasq " "nvme_start_ctrl failed because the admin submission queue address is null" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_err_startfail_nbarasq(void)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_nbarasq();
    }
}

#define TRACE_NVME_ERR_STARTFAIL_NBARACQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_NBARACQ) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_nbaracq(void)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_NBARACQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_nbaracq " "nvme_start_ctrl failed because the admin completion queue address is null" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_err_startfail_nbaracq(void)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_nbaracq();
    }
}

#define TRACE_NVME_ERR_STARTFAIL_ASQ_MISALIGNED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_ASQ_MISALIGNED) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_asq_misaligned(uint64_t addr)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_ASQ_MISALIGNED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_asq_misaligned " "nvme_start_ctrl failed because the admin submission queue address is misaligned: 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr);
    }
}

static inline void trace_nvme_err_startfail_asq_misaligned(uint64_t addr)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_asq_misaligned(addr);
    }
}

#define TRACE_NVME_ERR_STARTFAIL_ACQ_MISALIGNED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_ACQ_MISALIGNED) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_acq_misaligned(uint64_t addr)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_ACQ_MISALIGNED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_acq_misaligned " "nvme_start_ctrl failed because the admin completion queue address is misaligned: 0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , addr);
    }
}

static inline void trace_nvme_err_startfail_acq_misaligned(uint64_t addr)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_acq_misaligned(addr);
    }
}

#define TRACE_NVME_ERR_STARTFAIL_PAGE_TOO_SMALL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_PAGE_TOO_SMALL) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_page_too_small(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_PAGE_TOO_SMALL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_page_too_small " "nvme_start_ctrl failed because the page size is too small: log2size=%u, min=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , log2ps, maxlog2ps);
    }
}

static inline void trace_nvme_err_startfail_page_too_small(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_page_too_small(log2ps, maxlog2ps);
    }
}

#define TRACE_NVME_ERR_STARTFAIL_PAGE_TOO_LARGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_PAGE_TOO_LARGE) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_page_too_large(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_PAGE_TOO_LARGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_page_too_large " "nvme_start_ctrl failed because the page size is too large: log2size=%u, max=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , log2ps, maxlog2ps);
    }
}

static inline void trace_nvme_err_startfail_page_too_large(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_page_too_large(log2ps, maxlog2ps);
    }
}

#define TRACE_NVME_ERR_STARTFAIL_CQENT_TOO_SMALL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_CQENT_TOO_SMALL) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_cqent_too_small(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_CQENT_TOO_SMALL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_cqent_too_small " "nvme_start_ctrl failed because the completion queue entry size is too small: log2size=%u, min=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , log2ps, maxlog2ps);
    }
}

static inline void trace_nvme_err_startfail_cqent_too_small(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_cqent_too_small(log2ps, maxlog2ps);
    }
}

#define TRACE_NVME_ERR_STARTFAIL_CQENT_TOO_LARGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_CQENT_TOO_LARGE) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_cqent_too_large(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_CQENT_TOO_LARGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_cqent_too_large " "nvme_start_ctrl failed because the completion queue entry size is too large: log2size=%u, max=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , log2ps, maxlog2ps);
    }
}

static inline void trace_nvme_err_startfail_cqent_too_large(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_cqent_too_large(log2ps, maxlog2ps);
    }
}

#define TRACE_NVME_ERR_STARTFAIL_SQENT_TOO_SMALL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_SQENT_TOO_SMALL) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_sqent_too_small(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_SQENT_TOO_SMALL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_sqent_too_small " "nvme_start_ctrl failed because the submission queue entry size is too small: log2size=%u, min=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , log2ps, maxlog2ps);
    }
}

static inline void trace_nvme_err_startfail_sqent_too_small(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_sqent_too_small(log2ps, maxlog2ps);
    }
}

#define TRACE_NVME_ERR_STARTFAIL_SQENT_TOO_LARGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_SQENT_TOO_LARGE) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_sqent_too_large(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_SQENT_TOO_LARGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_sqent_too_large " "nvme_start_ctrl failed because the submission queue entry size is too large: log2size=%u, max=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , log2ps, maxlog2ps);
    }
}

static inline void trace_nvme_err_startfail_sqent_too_large(uint8_t log2ps, uint8_t maxlog2ps)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_sqent_too_large(log2ps, maxlog2ps);
    }
}

#define TRACE_NVME_ERR_STARTFAIL_ASQENT_SZ_ZERO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_ASQENT_SZ_ZERO) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_asqent_sz_zero(void)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_ASQENT_SZ_ZERO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_asqent_sz_zero " "nvme_start_ctrl failed because the admin submission queue size is zero" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_err_startfail_asqent_sz_zero(void)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_asqent_sz_zero();
    }
}

#define TRACE_NVME_ERR_STARTFAIL_ACQENT_SZ_ZERO_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL_ACQENT_SZ_ZERO) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail_acqent_sz_zero(void)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL_ACQENT_SZ_ZERO) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail_acqent_sz_zero " "nvme_start_ctrl failed because the admin completion queue size is zero" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_err_startfail_acqent_sz_zero(void)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail_acqent_sz_zero();
    }
}

#define TRACE_NVME_ERR_STARTFAIL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_ERR_STARTFAIL) || \
    false)

static inline void _nocheck__trace_nvme_err_startfail(void)
{
    if (trace_event_get_state(TRACE_NVME_ERR_STARTFAIL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_err_startfail " "setting controller enable bit failed" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_err_startfail(void)
{
    if (true) {
        _nocheck__trace_nvme_err_startfail();
    }
}

#define TRACE_NVME_UB_MMIOWR_MISALIGNED32_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_MMIOWR_MISALIGNED32) || \
    false)

static inline void _nocheck__trace_nvme_ub_mmiowr_misaligned32(uint64_t offset)
{
    if (trace_event_get_state(TRACE_NVME_UB_MMIOWR_MISALIGNED32) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_mmiowr_misaligned32 " "MMIO write not 32-bit aligned, offset=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_nvme_ub_mmiowr_misaligned32(uint64_t offset)
{
    if (true) {
        _nocheck__trace_nvme_ub_mmiowr_misaligned32(offset);
    }
}

#define TRACE_NVME_UB_MMIOWR_TOOSMALL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_MMIOWR_TOOSMALL) || \
    false)

static inline void _nocheck__trace_nvme_ub_mmiowr_toosmall(uint64_t offset, unsigned size)
{
    if (trace_event_get_state(TRACE_NVME_UB_MMIOWR_TOOSMALL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_mmiowr_toosmall " "MMIO write smaller than 32 bits, offset=0x%"PRIx64", size=%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, size);
    }
}

static inline void trace_nvme_ub_mmiowr_toosmall(uint64_t offset, unsigned size)
{
    if (true) {
        _nocheck__trace_nvme_ub_mmiowr_toosmall(offset, size);
    }
}

#define TRACE_NVME_UB_MMIOWR_INTMASK_WITH_MSIX_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_MMIOWR_INTMASK_WITH_MSIX) || \
    false)

static inline void _nocheck__trace_nvme_ub_mmiowr_intmask_with_msix(void)
{
    if (trace_event_get_state(TRACE_NVME_UB_MMIOWR_INTMASK_WITH_MSIX) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_mmiowr_intmask_with_msix " "undefined access to interrupt mask set when MSI-X is enabled" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_ub_mmiowr_intmask_with_msix(void)
{
    if (true) {
        _nocheck__trace_nvme_ub_mmiowr_intmask_with_msix();
    }
}

#define TRACE_NVME_UB_MMIOWR_RO_CSTS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_MMIOWR_RO_CSTS) || \
    false)

static inline void _nocheck__trace_nvme_ub_mmiowr_ro_csts(void)
{
    if (trace_event_get_state(TRACE_NVME_UB_MMIOWR_RO_CSTS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_mmiowr_ro_csts " "attempted to set a read only bit of controller status" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_ub_mmiowr_ro_csts(void)
{
    if (true) {
        _nocheck__trace_nvme_ub_mmiowr_ro_csts();
    }
}

#define TRACE_NVME_UB_MMIOWR_SSRESET_W1C_UNSUPPORTED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_MMIOWR_SSRESET_W1C_UNSUPPORTED) || \
    false)

static inline void _nocheck__trace_nvme_ub_mmiowr_ssreset_w1c_unsupported(void)
{
    if (trace_event_get_state(TRACE_NVME_UB_MMIOWR_SSRESET_W1C_UNSUPPORTED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_mmiowr_ssreset_w1c_unsupported " "attempted to W1C CSTS.NSSRO but CAP.NSSRS is zero (not supported)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_ub_mmiowr_ssreset_w1c_unsupported(void)
{
    if (true) {
        _nocheck__trace_nvme_ub_mmiowr_ssreset_w1c_unsupported();
    }
}

#define TRACE_NVME_UB_MMIOWR_SSRESET_UNSUPPORTED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_MMIOWR_SSRESET_UNSUPPORTED) || \
    false)

static inline void _nocheck__trace_nvme_ub_mmiowr_ssreset_unsupported(void)
{
    if (trace_event_get_state(TRACE_NVME_UB_MMIOWR_SSRESET_UNSUPPORTED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_mmiowr_ssreset_unsupported " "attempted NVM subsystem reset but CAP.NSSRS is zero (not supported)" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_ub_mmiowr_ssreset_unsupported(void)
{
    if (true) {
        _nocheck__trace_nvme_ub_mmiowr_ssreset_unsupported();
    }
}

#define TRACE_NVME_UB_MMIOWR_CMBLOC_RESERVED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_MMIOWR_CMBLOC_RESERVED) || \
    false)

static inline void _nocheck__trace_nvme_ub_mmiowr_cmbloc_reserved(void)
{
    if (trace_event_get_state(TRACE_NVME_UB_MMIOWR_CMBLOC_RESERVED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_mmiowr_cmbloc_reserved " "invalid write to reserved CMBLOC when CMBSZ is zero, ignored" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_ub_mmiowr_cmbloc_reserved(void)
{
    if (true) {
        _nocheck__trace_nvme_ub_mmiowr_cmbloc_reserved();
    }
}

#define TRACE_NVME_UB_MMIOWR_CMBSZ_READONLY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_MMIOWR_CMBSZ_READONLY) || \
    false)

static inline void _nocheck__trace_nvme_ub_mmiowr_cmbsz_readonly(void)
{
    if (trace_event_get_state(TRACE_NVME_UB_MMIOWR_CMBSZ_READONLY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_mmiowr_cmbsz_readonly " "invalid write to read only CMBSZ, ignored" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_nvme_ub_mmiowr_cmbsz_readonly(void)
{
    if (true) {
        _nocheck__trace_nvme_ub_mmiowr_cmbsz_readonly();
    }
}

#define TRACE_NVME_UB_MMIOWR_INVALID_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_MMIOWR_INVALID) || \
    false)

static inline void _nocheck__trace_nvme_ub_mmiowr_invalid(uint64_t offset, uint64_t data)
{
    if (trace_event_get_state(TRACE_NVME_UB_MMIOWR_INVALID) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_mmiowr_invalid " "invalid MMIO write, offset=0x%"PRIx64", data=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, data);
    }
}

static inline void trace_nvme_ub_mmiowr_invalid(uint64_t offset, uint64_t data)
{
    if (true) {
        _nocheck__trace_nvme_ub_mmiowr_invalid(offset, data);
    }
}

#define TRACE_NVME_UB_MMIORD_MISALIGNED32_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_MMIORD_MISALIGNED32) || \
    false)

static inline void _nocheck__trace_nvme_ub_mmiord_misaligned32(uint64_t offset)
{
    if (trace_event_get_state(TRACE_NVME_UB_MMIORD_MISALIGNED32) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_mmiord_misaligned32 " "MMIO read not 32-bit aligned, offset=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_nvme_ub_mmiord_misaligned32(uint64_t offset)
{
    if (true) {
        _nocheck__trace_nvme_ub_mmiord_misaligned32(offset);
    }
}

#define TRACE_NVME_UB_MMIORD_TOOSMALL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_MMIORD_TOOSMALL) || \
    false)

static inline void _nocheck__trace_nvme_ub_mmiord_toosmall(uint64_t offset)
{
    if (trace_event_get_state(TRACE_NVME_UB_MMIORD_TOOSMALL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_mmiord_toosmall " "MMIO read smaller than 32-bits, offset=0x%"PRIx64"" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_nvme_ub_mmiord_toosmall(uint64_t offset)
{
    if (true) {
        _nocheck__trace_nvme_ub_mmiord_toosmall(offset);
    }
}

#define TRACE_NVME_UB_MMIORD_INVALID_OFS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_MMIORD_INVALID_OFS) || \
    false)

static inline void _nocheck__trace_nvme_ub_mmiord_invalid_ofs(uint64_t offset)
{
    if (trace_event_get_state(TRACE_NVME_UB_MMIORD_INVALID_OFS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_mmiord_invalid_ofs " "MMIO read beyond last register, offset=0x%"PRIx64", returning 0" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_nvme_ub_mmiord_invalid_ofs(uint64_t offset)
{
    if (true) {
        _nocheck__trace_nvme_ub_mmiord_invalid_ofs(offset);
    }
}

#define TRACE_NVME_UB_DB_WR_MISALIGNED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_DB_WR_MISALIGNED) || \
    false)

static inline void _nocheck__trace_nvme_ub_db_wr_misaligned(uint64_t offset)
{
    if (trace_event_get_state(TRACE_NVME_UB_DB_WR_MISALIGNED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_db_wr_misaligned " "doorbell write not 32-bit aligned, offset=0x%"PRIx64", ignoring" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_nvme_ub_db_wr_misaligned(uint64_t offset)
{
    if (true) {
        _nocheck__trace_nvme_ub_db_wr_misaligned(offset);
    }
}

#define TRACE_NVME_UB_DB_WR_INVALID_CQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_DB_WR_INVALID_CQ) || \
    false)

static inline void _nocheck__trace_nvme_ub_db_wr_invalid_cq(uint32_t qid)
{
    if (trace_event_get_state(TRACE_NVME_UB_DB_WR_INVALID_CQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_db_wr_invalid_cq " "completion queue doorbell write for nonexistent queue, cqid=%"PRIu32", ignoring" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qid);
    }
}

static inline void trace_nvme_ub_db_wr_invalid_cq(uint32_t qid)
{
    if (true) {
        _nocheck__trace_nvme_ub_db_wr_invalid_cq(qid);
    }
}

#define TRACE_NVME_UB_DB_WR_INVALID_CQHEAD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_DB_WR_INVALID_CQHEAD) || \
    false)

static inline void _nocheck__trace_nvme_ub_db_wr_invalid_cqhead(uint32_t qid, uint16_t new_head)
{
    if (trace_event_get_state(TRACE_NVME_UB_DB_WR_INVALID_CQHEAD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_db_wr_invalid_cqhead " "completion queue doorbell write value beyond queue size, cqid=%"PRIu32", new_head=%"PRIu16", ignoring" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qid, new_head);
    }
}

static inline void trace_nvme_ub_db_wr_invalid_cqhead(uint32_t qid, uint16_t new_head)
{
    if (true) {
        _nocheck__trace_nvme_ub_db_wr_invalid_cqhead(qid, new_head);
    }
}

#define TRACE_NVME_UB_DB_WR_INVALID_SQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_DB_WR_INVALID_SQ) || \
    false)

static inline void _nocheck__trace_nvme_ub_db_wr_invalid_sq(uint32_t qid)
{
    if (trace_event_get_state(TRACE_NVME_UB_DB_WR_INVALID_SQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_db_wr_invalid_sq " "submission queue doorbell write for nonexistent queue, sqid=%"PRIu32", ignoring" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qid);
    }
}

static inline void trace_nvme_ub_db_wr_invalid_sq(uint32_t qid)
{
    if (true) {
        _nocheck__trace_nvme_ub_db_wr_invalid_sq(qid);
    }
}

#define TRACE_NVME_UB_DB_WR_INVALID_SQTAIL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_NVME_UB_DB_WR_INVALID_SQTAIL) || \
    false)

static inline void _nocheck__trace_nvme_ub_db_wr_invalid_sqtail(uint32_t qid, uint16_t new_tail)
{
    if (trace_event_get_state(TRACE_NVME_UB_DB_WR_INVALID_SQTAIL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:nvme_ub_db_wr_invalid_sqtail " "submission queue doorbell write value beyond queue size, sqid=%"PRIu32", new_head=%"PRIu16", ignoring" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , qid, new_tail);
    }
}

static inline void trace_nvme_ub_db_wr_invalid_sqtail(uint32_t qid, uint16_t new_tail)
{
    if (true) {
        _nocheck__trace_nvme_ub_db_wr_invalid_sqtail(qid, new_tail);
    }
}

#define TRACE_XEN_BLOCK_REALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_REALIZE) || \
    false)

static inline void _nocheck__trace_xen_block_realize(const char * type, uint32_t disk, uint32_t partition)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_REALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_realize " "%s d%up%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, disk, partition);
    }
}

static inline void trace_xen_block_realize(const char * type, uint32_t disk, uint32_t partition)
{
    if (true) {
        _nocheck__trace_xen_block_realize(type, disk, partition);
    }
}

#define TRACE_XEN_BLOCK_CONNECT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_CONNECT) || \
    false)

static inline void _nocheck__trace_xen_block_connect(const char * type, uint32_t disk, uint32_t partition)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_CONNECT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_connect " "%s d%up%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, disk, partition);
    }
}

static inline void trace_xen_block_connect(const char * type, uint32_t disk, uint32_t partition)
{
    if (true) {
        _nocheck__trace_xen_block_connect(type, disk, partition);
    }
}

#define TRACE_XEN_BLOCK_DISCONNECT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_DISCONNECT) || \
    false)

static inline void _nocheck__trace_xen_block_disconnect(const char * type, uint32_t disk, uint32_t partition)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_DISCONNECT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_disconnect " "%s d%up%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, disk, partition);
    }
}

static inline void trace_xen_block_disconnect(const char * type, uint32_t disk, uint32_t partition)
{
    if (true) {
        _nocheck__trace_xen_block_disconnect(type, disk, partition);
    }
}

#define TRACE_XEN_BLOCK_UNREALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_UNREALIZE) || \
    false)

static inline void _nocheck__trace_xen_block_unrealize(const char * type, uint32_t disk, uint32_t partition)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_UNREALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_unrealize " "%s d%up%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, disk, partition);
    }
}

static inline void trace_xen_block_unrealize(const char * type, uint32_t disk, uint32_t partition)
{
    if (true) {
        _nocheck__trace_xen_block_unrealize(type, disk, partition);
    }
}

#define TRACE_XEN_BLOCK_SIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_SIZE) || \
    false)

static inline void _nocheck__trace_xen_block_size(const char * type, uint32_t disk, uint32_t partition, int64_t sectors)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_SIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_size " "%s d%up%u %"PRIi64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , type, disk, partition, sectors);
    }
}

static inline void trace_xen_block_size(const char * type, uint32_t disk, uint32_t partition, int64_t sectors)
{
    if (true) {
        _nocheck__trace_xen_block_size(type, disk, partition, sectors);
    }
}

#define TRACE_XEN_DISK_REALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_DISK_REALIZE) || \
    false)

static inline void _nocheck__trace_xen_disk_realize(void)
{
    if (trace_event_get_state(TRACE_XEN_DISK_REALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_disk_realize " "" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_xen_disk_realize(void)
{
    if (true) {
        _nocheck__trace_xen_disk_realize();
    }
}

#define TRACE_XEN_DISK_UNREALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_DISK_UNREALIZE) || \
    false)

static inline void _nocheck__trace_xen_disk_unrealize(void)
{
    if (trace_event_get_state(TRACE_XEN_DISK_UNREALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_disk_unrealize " "" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_xen_disk_unrealize(void)
{
    if (true) {
        _nocheck__trace_xen_disk_unrealize();
    }
}

#define TRACE_XEN_CDROM_REALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_CDROM_REALIZE) || \
    false)

static inline void _nocheck__trace_xen_cdrom_realize(void)
{
    if (trace_event_get_state(TRACE_XEN_CDROM_REALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_cdrom_realize " "" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_xen_cdrom_realize(void)
{
    if (true) {
        _nocheck__trace_xen_cdrom_realize();
    }
}

#define TRACE_XEN_CDROM_UNREALIZE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_CDROM_UNREALIZE) || \
    false)

static inline void _nocheck__trace_xen_cdrom_unrealize(void)
{
    if (trace_event_get_state(TRACE_XEN_CDROM_UNREALIZE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_cdrom_unrealize " "" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_xen_cdrom_unrealize(void)
{
    if (true) {
        _nocheck__trace_xen_cdrom_unrealize();
    }
}

#define TRACE_XEN_BLOCK_BLOCKDEV_ADD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_BLOCKDEV_ADD) || \
    false)

static inline void _nocheck__trace_xen_block_blockdev_add(char * str)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_BLOCKDEV_ADD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_blockdev_add " "%s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , str);
    }
}

static inline void trace_xen_block_blockdev_add(char * str)
{
    if (true) {
        _nocheck__trace_xen_block_blockdev_add(str);
    }
}

#define TRACE_XEN_BLOCK_BLOCKDEV_DEL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_BLOCKDEV_DEL) || \
    false)

static inline void _nocheck__trace_xen_block_blockdev_del(const char * node_name)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_BLOCKDEV_DEL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_blockdev_del " "%s" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , node_name);
    }
}

static inline void trace_xen_block_blockdev_del(const char * node_name)
{
    if (true) {
        _nocheck__trace_xen_block_blockdev_del(node_name);
    }
}

#define TRACE_XEN_BLOCK_DEVICE_CREATE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_DEVICE_CREATE) || \
    false)

static inline void _nocheck__trace_xen_block_device_create(unsigned int number)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_DEVICE_CREATE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_device_create " "%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , number);
    }
}

static inline void trace_xen_block_device_create(unsigned int number)
{
    if (true) {
        _nocheck__trace_xen_block_device_create(number);
    }
}

#define TRACE_XEN_BLOCK_DEVICE_DESTROY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_XEN_BLOCK_DEVICE_DESTROY) || \
    false)

static inline void _nocheck__trace_xen_block_device_destroy(unsigned int number)
{
    if (trace_event_get_state(TRACE_XEN_BLOCK_DEVICE_DESTROY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:xen_block_device_destroy " "%u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , number);
    }
}

static inline void trace_xen_block_device_destroy(unsigned int number)
{
    if (true) {
        _nocheck__trace_xen_block_device_destroy(number);
    }
}
#endif /* TRACE_HW_BLOCK_GENERATED_TRACERS_H */
